[metadata]
name = s3dups
author = Luke Plausin
author-email = luke.plausin@jha.com
summary = Python utility for finding duplicate files in S3
description-file = README.md
description-content-type = text/markdown; charset=UTF-8
home-page = https://github.com/lukeplausin/s3-duplicate-finder
project_urls =
    Bug Tracker = https://github.com/lukeplausin/s3-duplicate-finder
    Documentation = https://github.com/lukeplausin/s3-duplicate-finder
    Source Code = https://github.com/lukeplausin/s3-duplicate-finder
license = MIT
classifier =
    Programming Language :: Python :: 3
    Natural Language :: English
    Intended Audience :: Developers
keywords =
    utilities
    python
    aws
    amazon
    s3
    duplicate
    usage
    cloud
    dups

[files]
packages =
    s3dups

# data_files =
#     etc/pbr = etc/*
#     etc/init =
#         pbr.packaging.conf
#         pbr.version.conf

[entry_points]
console_scripts =
    s3dups = s3dups:main
pbr.config.drivers =
    plain = pbr.cfg.driver:Plain
